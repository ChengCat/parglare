{
    "docs": [
        {
            "location": "/",
            "text": "A pure Python (G)LR parser with integrated scanner.\n\n\n\n\nNote\n\n\nThe docs are work in progress.\n\n\n\n\nFeature highlights\n\u00b6\n\n\n\n\n\n\nScannerless parsing\n\n\nThere is no lexing as a separate phase. There is no separate lexer grammar.\nThe parser will try to reconize token during parsing at the given location.\nThis brings more parsing power as there are no lexical ambiguities\nintroduced by a separate lexing stage. You want variable names in your\nlanguage to be allowed to be keyword names? No problem.\n\n\n\n\n\n\nGeneralized parsing - GLR\n\n\nparglare gives you powerful tools to see where non-determinism in your\ngrammar lies (the notorious shift-reduce and reduce-reduce conflicts) and\ngives detailed info on why that happened. In case your language needs\nnon-deterministic parsing, either it needs additional lookahead to decide or\nyour language is inherently ambiguous, you can resort to the GLR algorithm\nby a simple change of the parser class. The grammar stays the same.\n\n\nIn the case of non-determinism (unability for a parser to deterministically\ndecide what to do) the parser will fork and investigate each possibility.\nEventualy, parsers that decided wrong will die leaving only the right one.\nIn case there are multiple interpretation of your input you will get all the\ntrees (a.k.a. \"the parse forest\").\n\n\n\n\n\n\nDeclarative associativity and priority rules\n\n\nThese problems arise a lot when building expression languages. Even a little\narithmetic expression as \n3 + 4 * 5 * 2\n have multiple interpretation\ndepending on the associativity and priority of operations. In parglare it is\neasy to specify these rules in the grammar (see the quick intro bellow\nor\n\nthe calc example\n).\n\n\n\n\n\n\nTracing/debuging, visualization and error reporting\n\n\nThere is an extensive support for grammar checking, debugging, automata\nvisualization, and parse tracing. Check out \ntodo: pglr command\n.\n\n\n\n\n\n\nParsing arbitrary list of object\n\n\nparglare is not used only to parse the textual content. It can parse (create\na tree) of an arbitrary list of objects (numbers, bytes, whatever) based on\nthe common parglare grammar. For this you have to\ndefine \ntodo: token recognizers\n for your input stream. The built-in\nrecognizers are string and regex recognizers for parsing textual inputs.\nSee \nrecognizers\n parameter to grammar construction in\nthe \ntest_parse_list_of_objects.py test\n.\n\n\n\n\n\n\nFlexible actions calling strategies\n\n\nDuring parsing you will want to do something when the grammar rule matches.\nThe whole point of parsing is that you want to transform your input to some\noutput. There are several options:\n- do nothing - this way your parser is a mere recognizer, it produces\n  nothing but just verifies that your input adhere to the grammar;\n- call default actions - the default actions will build a parse tree.\n- call user supplied actions - you write a Python function that is called\n  when the rule matches. You can do whatever you want at this place and the\n  result returned is used in parent rules/actions.\n\n\nBesides calling your actions in-line - during the parsing process - you can\ndecide to build the tree first and call custom actions afterwards. This is a\ngood option if you want to evaluate your tree in a multiple ways or if you\nare using GLR and want to be sure that actions are called only for the\nsurviving tree.\n\n\n\n\n\n\nSupport for whitespaces/comments\n\n\nSupport for language comments/whitespaces is done using the special rule\n\nLAYOUT\n. By default whitespaces are skipped. This is controlled by \nws\n\nparameter to the parser constructor which is by default set to \n\\t\\n\n. If\nset to \nNone\n no whitespace skipping is provided. If there is a rule\n\nLAYOUT\n in the grammar this rule is used instead. An additional parser with\nthe layout grammar will be built to handle whitespaces.\n\n\n\n\n\n\nError recovery (not for GLR at the moment)\n\n\nThis is something that often lacks in parsing libraries. More often than not\nyou will want your parser to recover from an error, report it, and continue\nparsing. parglare has a built-in error recovery strategy which is currently\na simplistic one -- it will skip current character and try to continue --\nbut gives you possibility to provide your own.\n\n\n\n\n\n\nTest coverage\n\n\nTest coverage is high and I'll try to keep it that way.\n\n\n\n\n\n\nTODO/Planed\n\u00b6\n\n\n\n\n\n\nDocs\n\n\nThis docs is currently work in progress. It should be done soon. Stay tuned.\n\n\n\n\n\n\nTable caching\n\n\nAt the moment parser tables are constructed on-the-fly which might be slow\nfor larger grammars. In the future tables will be recalculated only if the\ngrammar has changed and cached.\n\n\n\n\n\n\nSpecify common actions in the grammar\n\n\nparglare provides some commonly used custom actions. It would reduce\nboiler-plate in specification of these actions if a syntax is added to provide\nthat information in the grammar directly.\n\n\nExample:\n\n\n@collect\nsome_objects = some_objects some_object | some_object;\n\n\n\n\n\n\n\nSupport for named matches\n\n\nAt the moment, as a parameter to action you get a list of matched elements. It\nwould be useful to reference these element by name rather than by position.\n\n\nmy_rule = first:first_match_rule second:second_match_rule;\nfirst_match_rule = ...;\nsecond_match_rule = ...;\n\n\n\nNow in your action for \nmy_rule\n you will get \nfirst\n and \nsecond\n as a parameters.\nThis would make it easy to provide a new common action that will return a Python\nobject with supplied parameters as object attributes.\n\n\n\n\n\n\nQuick intro\n\u00b6\n\n\nThis is just a small example to get the general idea. This example shows how to\nparse and evaluate expressions with 5 operations with different priority and\nassociativity. Evaluation is done using semantic/reduction actions.\n\n\nThe whole expression evaluator is done in under 30 lines of code!\n\n\nUntil docs is completed\nsee\n\nthe example folder\n and\n\ntests\n for\nmore.\n\n\nfrom parglare import Parser, Grammar\n\ngrammar = r\"\"\"\nE = E '+' E  {left, 1}\n  | E '-' E  {left, 1}\n  | E '*' E  {left, 2}\n  | E '/' E  {left, 2}\n  | E '^' E  {right, 3}\n  | '(' E ')'\n  | number;\nnumber = /\\d+(\\.\\d+)?/;\n\"\"\"\n\nactions = {\n    \"E\": [lambda _, nodes: nodes[0] + nodes[2],\n          lambda _, nodes: nodes[0] - nodes[2],\n          lambda _, nodes: nodes[0] * nodes[2],\n          lambda _, nodes: nodes[0] / nodes[2],\n          lambda _, nodes: nodes[0] ** nodes[2],\n          lambda _, nodes: nodes[1],\n          lambda _, nodes: nodes[0]],\n    \"number\": lambda _, value: float(value),\n}\n\ng = Grammar.from_string(grammar)\nparser = Parser(g, debug=True, actions=actions)\n\nresult = parser.parse(\"34 + 4.6 / 2 * 4^2^2 + 78\")\n\nprint(\"Result = \", result)\n\n# Output\n# -- Debuging/tracing output with detailed info about grammar, productions,\n# -- terminals and nonterminals, DFA states, parsing progress,\n# -- and at the end of the output:\n# Result = 700.8\n\n\n\n\nNote on LR tables calculation\n\u00b6\n\n\nparglare provides both SLR and LALR tables calculation (LALR is the default).\nLALR is modified to avoid REDUCE/REDUCE conflicts on state merging. Although\nnot proven, this should enable handling of all LR(1) grammars with reduced set\nof states and without conflicts. For grammars that are not LR(1) a GLR parsing\nis provided.\n\n\nNote on lexical disambiguation\n\u00b6\n\n\nLexical ambiguity arise if multiple recognizers match at the same location.\nLexical disambiguation is done in the following order:\n\n\n\n\nPriorities are used first.\n\n\nString recognizers are preferred over regexes (i.e. the most specific match).\n\n\nThe longest-match strategy is used if multiple regexes matches with the same\n  priority. For further disambiguation if longest-match fails \nprefer\n rule\n  may be given in terminal definition.\n\n\n\n\nWhat does \nparglare\n mean?\n\u00b6\n\n\nIt is an amalgam of the words \nparser\n and \nglare\n where the second word is\nchosen to contain letters GLR and to be easy for pronunciation. I also like one\nof the translations for the word - \nto be very bright and intense\n\n(by \nThe Free Dictionary\n)\n\n\nOh, and the name is non-generic and unique which make it easy to find on the\nnet. ;)\n\n\nLicense\n\u00b6\n\n\nMIT\n\n\nPython versions\n\u00b6\n\n\nTested with 2.7, 3.3-3.6",
            "title": "Home"
        },
        {
            "location": "/#feature-highlights",
            "text": "Scannerless parsing  There is no lexing as a separate phase. There is no separate lexer grammar.\nThe parser will try to reconize token during parsing at the given location.\nThis brings more parsing power as there are no lexical ambiguities\nintroduced by a separate lexing stage. You want variable names in your\nlanguage to be allowed to be keyword names? No problem.    Generalized parsing - GLR  parglare gives you powerful tools to see where non-determinism in your\ngrammar lies (the notorious shift-reduce and reduce-reduce conflicts) and\ngives detailed info on why that happened. In case your language needs\nnon-deterministic parsing, either it needs additional lookahead to decide or\nyour language is inherently ambiguous, you can resort to the GLR algorithm\nby a simple change of the parser class. The grammar stays the same.  In the case of non-determinism (unability for a parser to deterministically\ndecide what to do) the parser will fork and investigate each possibility.\nEventualy, parsers that decided wrong will die leaving only the right one.\nIn case there are multiple interpretation of your input you will get all the\ntrees (a.k.a. \"the parse forest\").    Declarative associativity and priority rules  These problems arise a lot when building expression languages. Even a little\narithmetic expression as  3 + 4 * 5 * 2  have multiple interpretation\ndepending on the associativity and priority of operations. In parglare it is\neasy to specify these rules in the grammar (see the quick intro bellow\nor the calc example ).    Tracing/debuging, visualization and error reporting  There is an extensive support for grammar checking, debugging, automata\nvisualization, and parse tracing. Check out  todo: pglr command .    Parsing arbitrary list of object  parglare is not used only to parse the textual content. It can parse (create\na tree) of an arbitrary list of objects (numbers, bytes, whatever) based on\nthe common parglare grammar. For this you have to\ndefine  todo: token recognizers  for your input stream. The built-in\nrecognizers are string and regex recognizers for parsing textual inputs.\nSee  recognizers  parameter to grammar construction in\nthe  test_parse_list_of_objects.py test .    Flexible actions calling strategies  During parsing you will want to do something when the grammar rule matches.\nThe whole point of parsing is that you want to transform your input to some\noutput. There are several options:\n- do nothing - this way your parser is a mere recognizer, it produces\n  nothing but just verifies that your input adhere to the grammar;\n- call default actions - the default actions will build a parse tree.\n- call user supplied actions - you write a Python function that is called\n  when the rule matches. You can do whatever you want at this place and the\n  result returned is used in parent rules/actions.  Besides calling your actions in-line - during the parsing process - you can\ndecide to build the tree first and call custom actions afterwards. This is a\ngood option if you want to evaluate your tree in a multiple ways or if you\nare using GLR and want to be sure that actions are called only for the\nsurviving tree.    Support for whitespaces/comments  Support for language comments/whitespaces is done using the special rule LAYOUT . By default whitespaces are skipped. This is controlled by  ws \nparameter to the parser constructor which is by default set to  \\t\\n . If\nset to  None  no whitespace skipping is provided. If there is a rule LAYOUT  in the grammar this rule is used instead. An additional parser with\nthe layout grammar will be built to handle whitespaces.    Error recovery (not for GLR at the moment)  This is something that often lacks in parsing libraries. More often than not\nyou will want your parser to recover from an error, report it, and continue\nparsing. parglare has a built-in error recovery strategy which is currently\na simplistic one -- it will skip current character and try to continue --\nbut gives you possibility to provide your own.    Test coverage  Test coverage is high and I'll try to keep it that way.",
            "title": "Feature highlights"
        },
        {
            "location": "/#todoplaned",
            "text": "Docs  This docs is currently work in progress. It should be done soon. Stay tuned.    Table caching  At the moment parser tables are constructed on-the-fly which might be slow\nfor larger grammars. In the future tables will be recalculated only if the\ngrammar has changed and cached.    Specify common actions in the grammar  parglare provides some commonly used custom actions. It would reduce\nboiler-plate in specification of these actions if a syntax is added to provide\nthat information in the grammar directly.  Example:  @collect\nsome_objects = some_objects some_object | some_object;    Support for named matches  At the moment, as a parameter to action you get a list of matched elements. It\nwould be useful to reference these element by name rather than by position.  my_rule = first:first_match_rule second:second_match_rule;\nfirst_match_rule = ...;\nsecond_match_rule = ...;  Now in your action for  my_rule  you will get  first  and  second  as a parameters.\nThis would make it easy to provide a new common action that will return a Python\nobject with supplied parameters as object attributes.",
            "title": "TODO/Planed"
        },
        {
            "location": "/#quick-intro",
            "text": "This is just a small example to get the general idea. This example shows how to\nparse and evaluate expressions with 5 operations with different priority and\nassociativity. Evaluation is done using semantic/reduction actions.  The whole expression evaluator is done in under 30 lines of code!  Until docs is completed\nsee the example folder  and tests  for\nmore.  from parglare import Parser, Grammar\n\ngrammar = r\"\"\"\nE = E '+' E  {left, 1}\n  | E '-' E  {left, 1}\n  | E '*' E  {left, 2}\n  | E '/' E  {left, 2}\n  | E '^' E  {right, 3}\n  | '(' E ')'\n  | number;\nnumber = /\\d+(\\.\\d+)?/;\n\"\"\"\n\nactions = {\n    \"E\": [lambda _, nodes: nodes[0] + nodes[2],\n          lambda _, nodes: nodes[0] - nodes[2],\n          lambda _, nodes: nodes[0] * nodes[2],\n          lambda _, nodes: nodes[0] / nodes[2],\n          lambda _, nodes: nodes[0] ** nodes[2],\n          lambda _, nodes: nodes[1],\n          lambda _, nodes: nodes[0]],\n    \"number\": lambda _, value: float(value),\n}\n\ng = Grammar.from_string(grammar)\nparser = Parser(g, debug=True, actions=actions)\n\nresult = parser.parse(\"34 + 4.6 / 2 * 4^2^2 + 78\")\n\nprint(\"Result = \", result)\n\n# Output\n# -- Debuging/tracing output with detailed info about grammar, productions,\n# -- terminals and nonterminals, DFA states, parsing progress,\n# -- and at the end of the output:\n# Result = 700.8",
            "title": "Quick intro"
        },
        {
            "location": "/#note-on-lr-tables-calculation",
            "text": "parglare provides both SLR and LALR tables calculation (LALR is the default).\nLALR is modified to avoid REDUCE/REDUCE conflicts on state merging. Although\nnot proven, this should enable handling of all LR(1) grammars with reduced set\nof states and without conflicts. For grammars that are not LR(1) a GLR parsing\nis provided.",
            "title": "Note on LR tables calculation"
        },
        {
            "location": "/#note-on-lexical-disambiguation",
            "text": "Lexical ambiguity arise if multiple recognizers match at the same location.\nLexical disambiguation is done in the following order:   Priorities are used first.  String recognizers are preferred over regexes (i.e. the most specific match).  The longest-match strategy is used if multiple regexes matches with the same\n  priority. For further disambiguation if longest-match fails  prefer  rule\n  may be given in terminal definition.",
            "title": "Note on lexical disambiguation"
        },
        {
            "location": "/#what-does-parglare-mean",
            "text": "It is an amalgam of the words  parser  and  glare  where the second word is\nchosen to contain letters GLR and to be easy for pronunciation. I also like one\nof the translations for the word -  to be very bright and intense \n(by  The Free Dictionary )  Oh, and the name is non-generic and unique which make it easy to find on the\nnet. ;)",
            "title": "What does parglare mean?"
        },
        {
            "location": "/#license",
            "text": "MIT",
            "title": "License"
        },
        {
            "location": "/#python-versions",
            "text": "Tested with 2.7, 3.3-3.6",
            "title": "Python versions"
        },
        {
            "location": "/grammar/",
            "text": "The parglare grammar language\n\u00b6\n\n\nparglare grammar specification language is based\non \nBNF\n. parglare is\nbased\non\n\nContext-Free Grammars (CFGs)\n and\ngrammar is given declaratively. You don't have to think about the parsing\nprocess like in\ne.g. \nPEGs\n.\nAmbiguities are dealt with explicitely (see section on conflicts...).\n\n\nGrammar consists of a set of derivation rules where each rule is of the form:\n\n\n<symbol> = <expression> ;\n\n\n\n\nwhere \n<symbol>\n is grammar non-terminal and \n<expression>\n is a sequence of\nterminals and non-terminals separated by choice operator \n|\n.\n\n\nFor example:\n\n\nFields = Field | Fields \",\" Field;\n\n\n\n\nHere \nFields\n is a non-terminal grammar symbol and it is defined as either a\nsingle \nField\n or, recursively, as \nFields\n followed by a string terminal \n,\n\nand than by another \nField\n. It is not given here by \nField\n might also be\ndefined as a non-terminal, for example:\n\n\nField = QuotedField | FieldContent;\n\n\n\n\nor it could be defined as a terminal:\n\n\nField = /[A-Z]*/\n\n\n\n\nThis terminal definition uses regular expression.\n\n\nIf you got use to various BNF extensions\n(like \nKleene star\n) you might find\nthis awkward because you must build \nzero or more\n or \none or more\n pattern from\nscratch using just a sequence, choice and recursion. The grammars are indeed\nmore verbose but, on the other hand, actions are much easier to write and you\nhave full control over tree construction process. parglare might provide some\nsyntactic sugar later that would make some constructs shorter to write.\n\n\nUsual patterns\n\u00b6\n\n\nOne or more\n\u00b6\n\n\ndocument = sections;\n// sections rule bellow will match one or more section.\nsections = sections section | section;\n\n\n\nIn this example \nsections\n will match one or more \nsection\n.\n\n\n\n\nNote\n\n\nBe aware that you could do the same with this rule:\n\n\nsections = section sections | section;\n\n\n\nwhich will give you similar result but the resulting tree will be different.\nFormer example will reduce sections early and than add another section to it,\nthus the tree will be expanding to the left. The later example will collect all\nthe sections and than start reducing from the end, thus building a tree\nexpanding to the right. These are subtle differences that are important when you\nstart writing your semantic actions. Most of the time you don't care about this\nso use the first version as it is slightly efficient and parglare provides\ncommon actions for these common cases.\n\n\n\n\nZero or more\n\u00b6\n\n\ndocument = sections;\n// sections rule bellow will match zero or more section.\nsections = sections section | section | EMPTY;\n\n\n\nIn this example \nsections\n will match zero or more \nsection\n. Notice the\naddition of the \nEMPTY\n choice at the end. This means that matching nothing is a\nvalid \nsections\n non-terminal.\n\n\nSame note from above applies here to.\n\n\nOptional\n\u00b6\n\n\ndocument = optheader body;\noptheader = header | EMPTY;\n\n\n\nIn this example \noptheader\n is either a header or nothing.\n\n\nGrammar comments\n\u00b6\n\n\nIn grammar comments are available as both line comments and block comments:\n\n\n// This is a line comment. Everything from the '//' to the end of line is a comment.\n\n/*\n  This is a block comment.\n  Everything in between `/*`  and '*/' is a comment.\n*/\n\n\n\nHandling whitespaces and comments\n\u00b6\n\n\nBy default parser will skip whitespaces. Whitespace skipping is controlled by\n\nws\n parameter to the parser which is by default set to \n'\\n\\t '\n.\n\n\nIf you need more control of the layout, i.e. handling of not only whitespaces by\ncomments also, you can use a special rule \nLAYOUT\n:\n\n\n  LAYOUT = LayoutItem | LAYOUT LayoutItem;\n  LayoutItem = WS | Comment | EMPTY;\n  WS = /\\s+/;\n  Comment = /\\/\\/.*/;\n\n\n\nThis will form a separate layout parser that will parse in-between each matched\ntokens. In this example spaces and line-comments will get consumed by the layout\nparser.\n\n\nIf this special rule is found in the grammar \nws\n parser parameter is ignored.\n\n\nAnother example that gives support for both line comments and block comments\nlike the one used in the grammar language itself:\n\n\n  LAYOUT = LayoutItem | LAYOUT LayoutItem;\n  LayoutItem = WS | Comment | EMPTY;\n  WS = /\\s+/;\n  Comment = '/*' CorNCs '*/' | /\\/\\/.*/;\n  CorNCs = CorNC | CorNCs CorNC | EMPTY;\n  CorNC = Comment | NotComment | WS;\n  NotComment = /((\\*[^\\/])|[^\\s*\\/]|\\/[^\\*])+/;",
            "title": "Grammar"
        },
        {
            "location": "/grammar/#the-parglare-grammar-language",
            "text": "parglare grammar specification language is based\non  BNF . parglare is\nbased\non Context-Free Grammars (CFGs)  and\ngrammar is given declaratively. You don't have to think about the parsing\nprocess like in\ne.g.  PEGs .\nAmbiguities are dealt with explicitely (see section on conflicts...).  Grammar consists of a set of derivation rules where each rule is of the form:  <symbol> = <expression> ;  where  <symbol>  is grammar non-terminal and  <expression>  is a sequence of\nterminals and non-terminals separated by choice operator  | .  For example:  Fields = Field | Fields \",\" Field;  Here  Fields  is a non-terminal grammar symbol and it is defined as either a\nsingle  Field  or, recursively, as  Fields  followed by a string terminal  , \nand than by another  Field . It is not given here by  Field  might also be\ndefined as a non-terminal, for example:  Field = QuotedField | FieldContent;  or it could be defined as a terminal:  Field = /[A-Z]*/  This terminal definition uses regular expression.  If you got use to various BNF extensions\n(like  Kleene star ) you might find\nthis awkward because you must build  zero or more  or  one or more  pattern from\nscratch using just a sequence, choice and recursion. The grammars are indeed\nmore verbose but, on the other hand, actions are much easier to write and you\nhave full control over tree construction process. parglare might provide some\nsyntactic sugar later that would make some constructs shorter to write.",
            "title": "The parglare grammar language"
        },
        {
            "location": "/grammar/#usual-patterns",
            "text": "",
            "title": "Usual patterns"
        },
        {
            "location": "/grammar/#one-or-more",
            "text": "document = sections;\n// sections rule bellow will match one or more section.\nsections = sections section | section;  In this example  sections  will match one or more  section .   Note  Be aware that you could do the same with this rule:  sections = section sections | section;  which will give you similar result but the resulting tree will be different.\nFormer example will reduce sections early and than add another section to it,\nthus the tree will be expanding to the left. The later example will collect all\nthe sections and than start reducing from the end, thus building a tree\nexpanding to the right. These are subtle differences that are important when you\nstart writing your semantic actions. Most of the time you don't care about this\nso use the first version as it is slightly efficient and parglare provides\ncommon actions for these common cases.",
            "title": "One or more"
        },
        {
            "location": "/grammar/#zero-or-more",
            "text": "document = sections;\n// sections rule bellow will match zero or more section.\nsections = sections section | section | EMPTY;  In this example  sections  will match zero or more  section . Notice the\naddition of the  EMPTY  choice at the end. This means that matching nothing is a\nvalid  sections  non-terminal.  Same note from above applies here to.",
            "title": "Zero or more"
        },
        {
            "location": "/grammar/#optional",
            "text": "document = optheader body;\noptheader = header | EMPTY;  In this example  optheader  is either a header or nothing.",
            "title": "Optional"
        },
        {
            "location": "/grammar/#grammar-comments",
            "text": "In grammar comments are available as both line comments and block comments:  // This is a line comment. Everything from the '//' to the end of line is a comment.\n\n/*\n  This is a block comment.\n  Everything in between `/*`  and '*/' is a comment.\n*/",
            "title": "Grammar comments"
        },
        {
            "location": "/grammar/#handling-whitespaces-and-comments",
            "text": "By default parser will skip whitespaces. Whitespace skipping is controlled by ws  parameter to the parser which is by default set to  '\\n\\t ' .  If you need more control of the layout, i.e. handling of not only whitespaces by\ncomments also, you can use a special rule  LAYOUT :    LAYOUT = LayoutItem | LAYOUT LayoutItem;\n  LayoutItem = WS | Comment | EMPTY;\n  WS = /\\s+/;\n  Comment = /\\/\\/.*/;  This will form a separate layout parser that will parse in-between each matched\ntokens. In this example spaces and line-comments will get consumed by the layout\nparser.  If this special rule is found in the grammar  ws  parser parameter is ignored.  Another example that gives support for both line comments and block comments\nlike the one used in the grammar language itself:    LAYOUT = LayoutItem | LAYOUT LayoutItem;\n  LayoutItem = WS | Comment | EMPTY;\n  WS = /\\s+/;\n  Comment = '/*' CorNCs '*/' | /\\/\\/.*/;\n  CorNCs = CorNC | CorNCs CorNC | EMPTY;\n  CorNC = Comment | NotComment | WS;\n  NotComment = /((\\*[^\\/])|[^\\s*\\/]|\\/[^\\*])+/;",
            "title": "Handling whitespaces and comments"
        },
        {
            "location": "/about/CONTRIBUTING/",
            "text": "Contributing\n\u00b6\n\n\nContributions are welcome, and they are greatly appreciated! Every\nlittle bit helps, and credit will always be given.\n\n\nYou can contribute in many ways:\n\n\nTypes of Contributions\n\u00b6\n\n\nReport Bugs\n\u00b6\n\n\nReport bugs at https://github.com/igordejanovic/parglare/issues.\n\n\nIf you are reporting a bug, please include:\n\n\n\n\nYour operating system name and version.\n\n\nAny details about your local setup that might be helpful in troubleshooting.\n\n\nDetailed steps to reproduce the bug.\n\n\n\n\nFix Bugs\n\u00b6\n\n\nLook through the GitHub issues for bugs. Anything tagged with \"bug\"\nand \"help wanted\" is open to whoever wants to implement it.\n\n\nImplement Features\n\u00b6\n\n\nLook through the GitHub issues for features. Anything tagged with \"enhancement\"\nand \"help wanted\" is open to whoever wants to implement it.\n\n\nWrite Documentation\n\u00b6\n\n\nparglare could always use more documentation, whether as part of the\nofficial parglare docs, in docstrings, or even on the web in blog posts,\narticles, and such.\n\n\nSubmit Feedback\n\u00b6\n\n\nThe best way to send feedback is to file an issue at https://github.com/igordejanovic/parglare/issues.\n\n\nIf you are proposing a feature:\n\n\n\n\nExplain in detail how it would work.\n\n\nKeep the scope as narrow as possible, to make it easier to implement.\n\n\nRemember that this is a volunteer-driven project, and that contributions\n  are welcome :)\n\n\n\n\nGet Started!\n\u00b6\n\n\nReady to contribute? Here's how to set up \nparglare\n for local development.\n\n\n\n\nFork the \nparglare\n repo on GitHub.\n\n\n\n\nClone your fork locally:\n\n\nbash\n  $ git clone git@github.com:your_name_here/parglare.git\n\n\n\n\n\n\nInstall your local copy into a virtualenv. Assuming you have\n   virtualenvwrapper installed, this is how you set up your fork for local\n   development:\n\n\nbash\n$ mkvirtualenv parglare\n$ cd parglare/\n$ python setup.py develop\n\n\n\n\n\n\nCreate a branch for local development::\n\n\nbash\n  $ git checkout -b name-of-your-bugfix-or-feature\n\n\n\n\n\n\nNow you can make your changes locally.\n\n\n\n\n\n\nWhen you're done making changes, check that your changes pass flake8 and the\n   tests, including testing other Python versions with tox:\n\n\nbash\n$ flake8 parglare tests\n$ python setup.py test or py.test\n$ tox\n\n\n\n\n\n\nTo get flake8 and tox, just pip install them into your virtualenv.\n\n\n\n\n\n\nCommit your changes and push your branch to GitHub:\n\n\nbash\n$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n\n\n\n\n\n\nSubmit a pull request through the GitHub website.\n\n\n\n\n\n\nPull Request Guidelines\n\u00b6\n\n\nBefore you submit a pull request, check that it meets these guidelines:\n\n\n\n\nThe pull request should include tests.\n\n\nIf the pull request adds functionality, the docs should be updated. Put\n   your new functionality into a function with a docstring, and add the\n   feature to the list in README.rst.\n\n\nThe pull request should work for Python 2.6, 2.7, 3.3-3.6, and for\n   PyPy. Check https://travis-ci.org/igordejanovic/parglare/pull_requests and\n   make sure that the tests pass for all supported Python versions.\n\n\n\n\nTips\n\u00b6\n\n\nTo run a subset of tests:\n\n\n$ py.test tests.test_parglare",
            "title": "Contributing"
        },
        {
            "location": "/about/CONTRIBUTING/#contributing",
            "text": "Contributions are welcome, and they are greatly appreciated! Every\nlittle bit helps, and credit will always be given.  You can contribute in many ways:",
            "title": "Contributing"
        },
        {
            "location": "/about/CONTRIBUTING/#types-of-contributions",
            "text": "",
            "title": "Types of Contributions"
        },
        {
            "location": "/about/CONTRIBUTING/#report-bugs",
            "text": "Report bugs at https://github.com/igordejanovic/parglare/issues.  If you are reporting a bug, please include:   Your operating system name and version.  Any details about your local setup that might be helpful in troubleshooting.  Detailed steps to reproduce the bug.",
            "title": "Report Bugs"
        },
        {
            "location": "/about/CONTRIBUTING/#fix-bugs",
            "text": "Look through the GitHub issues for bugs. Anything tagged with \"bug\"\nand \"help wanted\" is open to whoever wants to implement it.",
            "title": "Fix Bugs"
        },
        {
            "location": "/about/CONTRIBUTING/#implement-features",
            "text": "Look through the GitHub issues for features. Anything tagged with \"enhancement\"\nand \"help wanted\" is open to whoever wants to implement it.",
            "title": "Implement Features"
        },
        {
            "location": "/about/CONTRIBUTING/#write-documentation",
            "text": "parglare could always use more documentation, whether as part of the\nofficial parglare docs, in docstrings, or even on the web in blog posts,\narticles, and such.",
            "title": "Write Documentation"
        },
        {
            "location": "/about/CONTRIBUTING/#submit-feedback",
            "text": "The best way to send feedback is to file an issue at https://github.com/igordejanovic/parglare/issues.  If you are proposing a feature:   Explain in detail how it would work.  Keep the scope as narrow as possible, to make it easier to implement.  Remember that this is a volunteer-driven project, and that contributions\n  are welcome :)",
            "title": "Submit Feedback"
        },
        {
            "location": "/about/CONTRIBUTING/#get-started",
            "text": "Ready to contribute? Here's how to set up  parglare  for local development.   Fork the  parglare  repo on GitHub.   Clone your fork locally:  bash\n  $ git clone git@github.com:your_name_here/parglare.git    Install your local copy into a virtualenv. Assuming you have\n   virtualenvwrapper installed, this is how you set up your fork for local\n   development:  bash\n$ mkvirtualenv parglare\n$ cd parglare/\n$ python setup.py develop    Create a branch for local development::  bash\n  $ git checkout -b name-of-your-bugfix-or-feature    Now you can make your changes locally.    When you're done making changes, check that your changes pass flake8 and the\n   tests, including testing other Python versions with tox:  bash\n$ flake8 parglare tests\n$ python setup.py test or py.test\n$ tox    To get flake8 and tox, just pip install them into your virtualenv.    Commit your changes and push your branch to GitHub:  bash\n$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature    Submit a pull request through the GitHub website.",
            "title": "Get Started!"
        },
        {
            "location": "/about/CONTRIBUTING/#pull-request-guidelines",
            "text": "Before you submit a pull request, check that it meets these guidelines:   The pull request should include tests.  If the pull request adds functionality, the docs should be updated. Put\n   your new functionality into a function with a docstring, and add the\n   feature to the list in README.rst.  The pull request should work for Python 2.6, 2.7, 3.3-3.6, and for\n   PyPy. Check https://travis-ci.org/igordejanovic/parglare/pull_requests and\n   make sure that the tests pass for all supported Python versions.",
            "title": "Pull Request Guidelines"
        },
        {
            "location": "/about/CONTRIBUTING/#tips",
            "text": "To run a subset of tests:  $ py.test tests.test_parglare",
            "title": "Tips"
        },
        {
            "location": "/about/LICENSE/",
            "text": "MIT License\n\n\nCopyright (c) 2016-2017, Igor R. Dejanovic\n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy of\nthis software and associated documentation files (the \"Software\"), to deal in\nthe Software without restriction, including without limitation the rights to\nuse, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\nthe Software, and to permit persons to whom the Software is furnished to do so,\nsubject to the following conditions:\n\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\nFOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\nCOPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\nIN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\nCONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.",
            "title": "License"
        }
    ]
}